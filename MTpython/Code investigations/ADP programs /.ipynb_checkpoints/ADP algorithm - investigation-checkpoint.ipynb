{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADP algorihtm \n",
    "- The goal of this file is to first learn how does the ADP work on a simple example and then use it to solve the problem of gas power plant valuation. \n",
    "\n",
    "- First, I will setup a simple example of three states and two actions. Each of the two actions changes the probability distributions of results and \"costs\" some reward. \n",
    "    - I will compute the optimal strategy for this example with real dynamic programming and then with the approximative dynamic programming. \n",
    "    - I will make heuristic strategies as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three states two actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/filiprolenec/Desktop/MT/MTpython/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_example.strategy as s\n",
    "from simple_example.simulation import run_simulation\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from simple_example.setup import SimpleProblemSetup\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from simple_example.state import get_new_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Dynamic programming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_example.dp_algorithm import classic_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_vf = [0,0,0]\n",
    "problem_setup = SimpleProblemSetup()\n",
    "prob_matrix = problem_setup.prob_matrix\n",
    "reward_matrix = problem_setup.reward_matrix\n",
    "time_epochs = problem_setup.time_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({9: {1: 2, 2: 1, 3: 2},\n",
       "  8: {1: 2, 2: 1, 3: 2},\n",
       "  7: {1: 2, 2: 1, 3: 2},\n",
       "  6: {1: 2, 2: 1, 3: 2},\n",
       "  5: {1: 2, 2: 1, 3: 2},\n",
       "  4: {1: 2, 2: 1, 3: 2},\n",
       "  3: {1: 2, 2: 1, 3: 2},\n",
       "  2: {1: 2, 2: 1, 3: 2},\n",
       "  1: {1: 2, 2: 1, 3: 2},\n",
       "  0: {1: 2, 2: 1, 3: 2}},\n",
       " {9: [6.3999999999999995, 13.8, 14.399999999999999],\n",
       "  8: [19.88, 26.48, 26.16],\n",
       "  7: [31.995999999999995, 38.768, 38.804],\n",
       "  6: [44.516, 51.2352, 51.1472],\n",
       "  5: [56.90168, 63.63856, 63.593039999999995],\n",
       "  4: [69.333008, 76.063872, 76.00384],\n",
       "  3: [81.7487632, 88.48168, 88.4266032],\n",
       "  2: [94.16983456, 100.90205055999999, 100.84528191999999],\n",
       "  1: [106.58909091199999, 113.321546176, 113.26535516799999],\n",
       "  0: [119.00896694399998, 125.7413405184, 125.6849522944]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_dp(horizon_vf, problem_setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [s.heuristic_strategy_0, \n",
    "              s.heuristic_strategy_1, \n",
    "              s.heuristic_strategy_2, \n",
    "              s.optimal_strategy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "initial_state = 0\n",
    "\n",
    "for strategy in strategies: \n",
    "    strategy_results = {}\n",
    "    for i in range(10000): \n",
    "        strategy_results[i] = run_simulation(strategy, initial_state, problem_setup)\n",
    "            \n",
    "    all_results[strategy.__name__] = strategy_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x124300af0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for strategy in strategies: \n",
    "    plt.hist(all_results[strategy.__name__].values(), label =strategy.__name__, alpha = 0.7)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.8166\n",
      "35.4347\n",
      "64.4868\n",
      "119.0866\n"
     ]
    }
   ],
   "source": [
    "for strategy in strategies: \n",
    "    print(np.mean(list(all_results[strategy.__name__].values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADP algorithm finding the best strategy \n",
    "$$V_t(s, \\theta) = \\theta_0 + \\theta_{t,1} \\cdot \\phi_1(s) + \\theta_{t,2} \\cdot \\phi_2(s) + \\theta_{t,3} \\cdot \\phi_3(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\phi_i(s)$ functions are onli indicator functions of each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADP steps: \n",
    "1. Initialize parameters $\\theta_t$\n",
    "2. Define basis functions $\\phi_i(s)$\n",
    "3. Loop over time epochs from the last to the first: \n",
    "    1. Loop over fixed amount of sampled states: \n",
    "        1. Determine optimal decisions based on those states, in my case 1 action out of 6. \n",
    "        2. Simulate what happens after my action (s,a,s) triplet and reward (plus value function estimate in the following state) \n",
    "    2. Make a linear regression on the new findings. Get new $\\theta_i$ based on rewards + future vf and values of the basis functions. \n",
    "    3. Update the parameters, either fully, or with a learning step. \n",
    "4. Check how far are the value functions from the truth (which I know here) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. initialize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = [[0 for i in range(3)] for i in time_epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_initial = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bf_1(s): \n",
    "    return 1 if s == 0 else 0 \n",
    "\n",
    "def bf_2(s): \n",
    "    return 1 if s == 1 else 0 \n",
    "\n",
    "def bf_3(s): \n",
    "    return 1 if s == 2 else 0 \n",
    "basis_functions = [bf_1,bf_2,bf_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a determine optimal decision based on a state and simulate what happens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_mult(a,b): \n",
    "    return sum([i*j for i,j in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 2\n",
    "action = 1\n",
    "actions = range(2)\n",
    "states = range(3)\n",
    "t = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.4, 0.3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_matrix[2][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 18, 14]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_setup.reward_matrix[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.399999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mult(prob_matrix[2][1], reward_matrix[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_example.vf import Vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vfs(time_epochs, theta_initial):\n",
    "    vfs = []\n",
    "    for i in time_epochs: \n",
    "        vfs.append(Vf(theta_initial))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_value(state, action, prob_matrix, reward_matrix, future_vf): \n",
    "    rewards = reward_matrix[state][action]\n",
    "    future_vf_values = future_vf.compute_all_values()\n",
    "    total_rewards = [i+j for i,j in zip(rewards, future_vf_values)]\n",
    "    return vector_mult(prob_matrix[state][action], total_rewards) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_action(state, future_vf, prob_matrix, reward_matrix): \n",
    "    exp_rewards = []\n",
    "    for action in actions: \n",
    "        exp_rewards.append(get_exp_value(state, action, prob_matrix, reward_matrix, future_vf))\n",
    "    return np.argmax(exp_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b for x random states, determine the best action, perform the evolution, get the actual reward and note it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_reward_pairs(sample_size, states, future_vf, prob_matrix, reward_matrix): \n",
    "    state_reward_pairs = []\n",
    "    for i in range(sample_size): \n",
    "        state = np.random.choice(states, p=[0.34, 0.33, 0.33])\n",
    "\n",
    "        action = get_best_action(state, future_vf, prob_matrix, reward_matrix) \n",
    "        new_state = get_new_state(state, action, prob_matrix)\n",
    "\n",
    "        reward = reward_matrix[state][action][new_state] + future_vf.compute_value(new_state)\n",
    "        state_reward_pairs.append([state, reward])\n",
    "    return state_reward_pairs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c linear regression on the results \n",
    "- I have the following model: \n",
    "$$V_t(s, \\theta) = \\theta_0 + \\theta_{t,1} \\cdot \\phi_1(s) + \\theta_{t,2} \\cdot \\phi_2(s) + \\theta_{t,3} \\cdot \\phi_3(s)$$\n",
    "- and I want to predict the parameters \\theta, based on the realizaitons V_t(s) and the variable s. \n",
    "- This model is simple, and we expect that each of the parameters will be close to the expected value. \n",
    "    - In reality, it will be such a number that minimizes the sum of squares of the errors. \n",
    "    - For example if there are three outcomes with 1/3 probability and rewards 1,3,100, the number will be closer to 50 than 33. \n",
    "    - Thus even for this model, the result will in uneven settings of reeward be only an approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Intercept makes the model crazy \n",
    "- There are numbers like 10^14 \n",
    "- Since there is no reason for the intercept, i will just make a model without it here. The model becomes: \n",
    "\n",
    "$$V_t(s, \\theta) = \\theta_{t,1} \\cdot \\phi_1(s) + \\theta_{t,2} \\cdot \\phi_2(s) + \\theta_{t,3} \\cdot \\phi_3(s)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing the regression variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_regression_variables(state_reward_pairs, basis_functions): \n",
    "    x = []\n",
    "    y = []\n",
    "    for pair in state_reward_pairs: \n",
    "        x.append([basis_functions[0](pair[0]),\n",
    "                  basis_functions[1](pair[0]),\n",
    "                  basis_functions[2](pair[0])])\n",
    "        y.append(pair[1])\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual values = 6.4, 13.8, 14.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But the actual prediction makes sense i guess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vf_coef(current_vf, next_vf, problem_setup, sample_size, basis_functions):\n",
    "    state_reward_pairs_raw = get_state_reward_pairs(sample_size, \n",
    "                                                    problem_setup.states, \n",
    "                                                    next_vf,\n",
    "                                                    problem_setup.prob_matrix,\n",
    "                                                    problem_setup.reward_matrix)\n",
    "    \n",
    "    x,y = prepare_regression_variables(state_reward_pairs_raw, basis_functions)\n",
    "    model = LinearRegression(fit_intercept=False).fit(x, y)\n",
    "    current_vf.set_params(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "106.58909091199999, 113.321546176, 113.26535516799999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with 5000 samples and 20 loops of update, there is still a 0.5% difference from the reality. This might be caused by a different optimization function as discussed above. Linear algorithm does not return the mean value, rather a value from which the sum of squares of residuals is the lowest. \n",
    "\n",
    "A reasonable approximation can be seen as low as for 50 samples and 10 loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_setup = SimpleProblemSetup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_example.adp_algorithm import adp_algorithm_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (20 of 20) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "vfs_1 = adp_algorithm_final(loops_of_update=20, sample_size=50, problem_setup = problem_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.30110875, 112.31663681, 106.60159761])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfs_1[0].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "106.58909091199999, 113.321546176, 113.26535516799999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:02:46 Time:  0:02:46\n"
     ]
    }
   ],
   "source": [
    "vfs_1 = adp_algorithm_final(loops_of_update=100, sample_size=2000, problem_setup = problem_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.43345844, 113.06374974, 112.84716716])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfs_1[0].params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "106.58909091199999, 113.321546176, 113.26535516799999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "- I have implemented the ADP algorithm on the simple example. \n",
    "- We can see that the approximation is really good in this example. The implementation is working. \n",
    "- This investigation will help with the implementation of the actual problem in the next phase. \n",
    "    - The complexity will rise significantly, each of the steps will be somehow harder and the computational complexity will rise too. Nevertheless, the framework is ready to be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# That was investigation for simple model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets discuss problems of ADP of the gas powerplant example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create random sample states in time t? \n",
    "- For price of gas I know the distribution, that distribution is just the lognormal process in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling price of gas and co2 prices. \n",
    "- Here the distribution is known. We know the behavior of the variables and log-normal process has a nice feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.exp(np.log(x1)+norm_1)\n",
    "x3 = np.exp(np.log(x2)+norm_2)\n",
    "\n",
    "x3 = np.exp(np.log(np.exp(np.log(x1)+norm_1))+norm_2)\n",
    "x3 = np.exp(np.log(x1)+norm_1+norm_2)\n",
    "\n",
    "x_t = np.exp(np.log(x1)+sum_{i=1, t-1} norm_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of normal variables has nice properties [here](https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables)\n",
    "- I have zero means, but I will need to multiply the volatility. Lets check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gas_price_in_t(sigma, x_start, time_epoch, sample_size):\n",
    "\n",
    "    prices = []\n",
    "    for i in range(sample_size): \n",
    "        x = x_start\n",
    "        for k in range(time_epoch):\n",
    "            x = np.exp(np.log(x)+np.random.normal(0, sigma, 1)[0])\n",
    "        prices.append(x)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gas_price_one_step(sigma, x_start, time_epochs, sample_size): \n",
    "    prices = [] \n",
    "    for i in range(sample_size): \n",
    "        x = np.exp(np.log(x_start)+ np.random.normal(0, sigma*np.sqrt(time_epochs), 1)[0])\n",
    "        prices.append(x)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_by_step = get_gas_price_in_t(0.015, 40, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_results = get_gas_price_one_step(0.015, 40,100,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(step_by_step, label =\"1\", alpha = 0.7, bins = 50)\n",
    "plt.hist(one_step_results, label =\"2\", alpha = 0.7, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ok "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling of prices of power. \n",
    "- Here it gets a little bit more complicated. \n",
    "- The volatility of power price depends on the government politics. \n",
    "- What we can do is to determine the average expected volatility through that time and compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_down = 0.04 \n",
    "prob_up = 0.08 \n",
    "zero_prob = 1 - prob_down - prob_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_gov_state(gov_state, prob_up, prob_down):\n",
    "    \n",
    "    zero_prob = 1 - prob_up - prob_down\n",
    "    current_move = np.random.choice(np.arange(1, 4), p=[prob_down, zero_prob, prob_up])-2\n",
    "\n",
    "    if gov_state+current_move in range(1,6): \n",
    "        gov_state += current_move\n",
    "    return gov_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_price_in_t(sigma_original, x_start, time_epoch, sample_size, prob_down, prob_up):\n",
    "\n",
    "    prices = []\n",
    "    for i in range(sample_size): \n",
    "        x = x_start\n",
    "        gov_policy = 1\n",
    "        for k in range(time_epoch):\n",
    "            sigma = sigma_original*(1+(gov_policy-1)*0.2)\n",
    "            x = np.exp(np.log(x)+np.random.normal(0, sigma, 1)[0])\n",
    "            gov_policy = get_next_gov_state(gov_policy, prob_up, prob_down)\n",
    "        prices.append(x)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_by_step = get_power_price_in_t (0.01, 40, 100, 10000, prob_down, prob_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following computation does not hold for such time epochs, where the value is 5. The value is never five. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_gov_policy_in_t(prob_up, prob_down, epoch): \n",
    "\n",
    "    return min(1+epoch*(prob_up-prob_down), 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_exp_policies(prob_up, prob_down, epochs): \n",
    "    return[get_exp_gov_policy_in_t(prob_up,prob_down,i) for i in range(epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_policies = get_avg_exp_policies(prob_up, prob_down, 100)\n",
    "sigmas = [0.01*(1+(gov_policy-1)*0.2) for gov_policy in exp_policies]\n",
    "sigmas_squared = [sigma*sigma for sigma in sigmas]\n",
    "sigma_average = np.sqrt(sum(sigmas_squared))/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a reasonable average sigma with which I could compute the power distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_result = get_gas_price_one_step(sigma_average, 40, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(step_by_step, label =\"1\", alpha = 0.7, bins = 50)\n",
    "plt.hist(one_step_result, label =\"2\", alpha = 0.7, bins = 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks also very reasonable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Government policy \n",
    "- Could also be computed, probably has something like a bounded binomial distribution or something like that. \n",
    "- What I will do is to get a reasonable amount of samples for all cases of government policy, with the majority around the expected value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gov_samples(epoch, prob_up, prob_down, sample_size):\n",
    "    exp_gov_policy = 1+(prob_up-prob_down)*epoch\n",
    "    raw_random_policies = np.random.normal(exp_gov_policy, 1, sample_size)    \n",
    "    return clean_policy_distribution(raw_random_policies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_policy_distribution(raw_random_policies): \n",
    "    clean_policies = []\n",
    "    for policy in raw_random_policies: \n",
    "        if policy<1: \n",
    "            clean_policies.append(1)\n",
    "        elif policy>5: \n",
    "            clean_policies.append(5)\n",
    "        else: \n",
    "            clean_policies.append(round(policy))\n",
    "    return clean_policies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_policies = get_gov_samples(35, prob_up, prob_down, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clean_policies, bins = 5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running state and powerplant states \n",
    "- Will be done heuristically \n",
    "    - Not build 5%\n",
    "    - Stage 1 40%\n",
    "    - Stage 2 50 % \n",
    "    - Sold 5%. \n",
    "    \n",
    "    \n",
    "    - Running 50% \n",
    "    - Not running 45% \n",
    "    - Mothballed 5% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance \n",
    "- some small number of realizations from -130M to 130M \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now everything at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50 \n",
    "sample_size = 30\n",
    "\n",
    "prob_up = 0.08\n",
    "prob_down = 0.04 \n",
    "\n",
    "gas_price = 13\n",
    "gas_volatility = 0.04\n",
    "\n",
    "co2_price = 9 \n",
    "co2_volatility = 0.025\n",
    "\n",
    "power_price =40 \n",
    "power_volatility = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lognormal_prices(start_price, time_epoch, sigma, sample_size): \n",
    "    return [np.exp(np.log(start_price)+ i) for i in np.random.normal(0, sigma*np.sqrt(time_epoch), sample_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_sigma_for_price(prob_up, prob_down, epoch, sigma):\n",
    "    exp_policies_by_epoch = get_avg_exp_policies(prob_up, prob_down, epoch)\n",
    "    sigmas = [sigma*(1+(epoch_policy-1)*0.2) for epoch_policy in exp_policies_by_epoch]\n",
    "    sigmas_squared = [sigma*sigma for sigma in sigmas]\n",
    "    sigma_average = np.sqrt(sum(sigmas_squared)/epoch)\n",
    "    return sigma_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_price_sample(prob_up, prob_down, epoch, power_volatility, sample_size, power_price): \n",
    "    avg_sigma = get_avg_sigma_for_price(prob_up, prob_down, epoch, power_volatility)\n",
    "    return get_lognormal_prices(power_price, epoch, avg_sigma, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gas_example.enum_types import PowerplantState\n",
    "from gas_example.enum_types import RunningState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_powerplant_state_sample(sample_size): \n",
    "    states = [] \n",
    "    for i in range(sample_size): \n",
    "        states.append(np.random.choice([PowerplantState.NOT_BUILT, \n",
    "                      PowerplantState.STAGE_1,\n",
    "                      PowerplantState.STAGE_2, \n",
    "                      PowerplantState.SOLD], \n",
    "                     p=[0.05, 0.4, 0.5, 0.05 ]))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_state_sample(sample_size): \n",
    "    states = [] \n",
    "    for i in range(sample_size): \n",
    "        states.append(np.random.choice([RunningState.RUNNING, \n",
    "                                        RunningState.NOT_RUNNING, \n",
    "                                        RunningState.MOTHBALLED], \n",
    "                                       p=[0.5, 0.45, 0.05]))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be done heuristically\n",
    "Not build 5%\n",
    "Stage 1 40%\n",
    "Stage 2 50 %\n",
    "Sold 5%.\n",
    "- Running 50% \n",
    "- Not running 45% \n",
    "- Mothballed 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance_sample(sample_size): \n",
    "    return np.random.uniform(-130_000_000,130_000_000,sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_price_sample = get_lognormal_prices(gas_price, epoch, gas_volatility, sample_size)\n",
    "co2_price_sample = get_lognormal_prices(co2_price, epoch, co2_volatility, sample_size)\n",
    "power_sample = get_power_price_sample(prob_up, prob_down, epoch, power_volatility, sample_size, power_price)\n",
    "clean_policies = get_gov_samples(epoch, prob_up, prob_down, sample_size)\n",
    "powerplant_state = get_powerplant_state_sample(sample_size)\n",
    "running_states = get_running_state_sample(sample_size)\n",
    "balance_sample = get_balance_sample(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is not possible to take a cartesian product of all of the individual samples. \n",
    "- We need to take a subsample, for example a 1000 rounds of choosing randomly a sample from each category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [gas_price_sample, \n",
    "          co2_price_sample, \n",
    "          power_sample, \n",
    "          clean_policies, \n",
    "          powerplant_state, \n",
    "          running_states, \n",
    "          balance_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "for sample in samples: \n",
    "    state.append(sample[np.random.choice(range(sample_size))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.949778701280625,\n",
       " 9.805471792634362,\n",
       " 54.18431876311155,\n",
       " 3,\n",
       " <PowerplantState.SOLD: 3>,\n",
       " <RunningState.RUNNING: 1>,\n",
       " -60423098.68493314]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
