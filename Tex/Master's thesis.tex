%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,czech,american]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=4cm,bmargin=3cm,lmargin=3cm,rmargin=2cm,headheight=0.8cm,headsep=1cm,footskip=0.5cm}
\pagestyle{headings}
\setcounter{secnumdepth}{3}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage[final]{pdfpages}
\usepackage{natbib}
\usepackage{mathrsfs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{caption}


\usepackage{array}
\usepackage{ragged2e}

\usepackage{lipsum}
\usepackage{psvectorian}

\DeclareMathOperator*{\argmax}{arg\,max}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
 \setlength{\leftmargin}{\labelwidth}
 \addtolength{\leftmargin}{\labelsep}
 \renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%% Font setup: please leave the LyX font settings all set to 'default'
%% if you want to use any of these packages:

%% Use Times New Roman font for text and Belleek font for math
%% Please make sure that the 'esint' package is turned off in the
%% 'Math options' page.
\usepackage[varg]{txfonts}

%% Use Utopia text with Fourier-GUTenberg math
%\usepackage{fourier}

%% Bitstream Charter text with Math Design math
%\usepackage[charter]{mathdesign}

%%---------------------------------------------------------------------

%% Make the multiline figure/table captions indent so that the second
%% line "hangs" right below the first one.
%\usepackage[format=hang]{caption}

%% Indent even the first paragraph in each section
\usepackage{indentfirst}

%%---------------------------------------------------------------------

%% Disable page numbers in the TOC. LOF, LOT (TOC automatically
%% adds \thispagestyle{chapter} if not overriden
%\addtocontents{toc}{\protect\thispagestyle{empty}}
%\addtocontents{lof}{\protect\thispagestyle{empty}}
%\addtocontents{lot}{\protect\thispagestyle{empty}}

%% Shifts the top line of the TOC (not the title) 1cm upwards 
%% so that the whole TOC fits on 1 page. Additional page size
%% adjustment is performed at the point where the TOC
%% is inserted.
%\addtocontents{toc}{\protect\vspace{-1cm}}

%%---------------------------------------------------------------------

% completely avoid orphans (first lines of a new paragraph on the bottom of a page)
\clubpenalty=9500

% completely avoid widows (last lines of paragraph on a new page)
\widowpenalty=9500

% disable hyphenation of acronyms
\hyphenation{CDFA HARDI HiPPIES IKEM InterTrack MEGIDDO MIMD MPFA DICOM ASCLEPIOS MedInria}

%%---------------------------------------------------------------------

%% Print out all vectors in bold type instead of printing an arrow above them
\renewcommand{\vec}[1]{\boldsymbol{#1}}

% Replace standard \cite by the parenthetical variant \citep
%\renewcommand{\cite}{\citep}

\makeatother

\usepackage{babel}

\newcommand{\ornamentleft}{%
	\psvectorian[width=2em]{2}%
}
\newcommand{\ornamentright}{%
	\psvectorian[width=2em,mirror]{2}%
}

\newcommand{\ornamentheader}[1]{%
	\begin{center}
		\ornamentleft
		\quad{\large\emph{#1}}\quad % style as desired
		\ornamentright
	\end{center}%
}

\newlength{\rlength}\setlength{\rlength}{16cm}
\newcommand{\ruletext}[2][\rlength]{%
	\noindent%
	\parbox{#1}{%
		\noindent\dotfill\raisebox{-.3\ht\strutbox}{#2}\dotfill\par}%
}





\begin{document}
\def\documentdate{July 7, 2017}

\newtheorem{definition}{Definition}[chapter]
\newtheorem{note}{Note}[chapter]
\newtheorem{example}{Example} 
\newtheorem{assumption}{Assumption} 

\newtheorem{theorem}{Theorem}
\newtheorem*{remark}{Remark}

\captionsetup[figure]{labelfont={bf},labelformat={default},labelsep=period,name={Fig.}}


\def\documentdate{\today}

\pagestyle{empty}
{\centering

\noindent %
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/cvut}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{0.6\linewidth}%
\begin{center}
\textsc{\large{}Czech Technical University in Prague}{\large{}}\\
{\large{}Faculty of Nuclear Sciences and Physical Engineering}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/fjfi}
\par\end{center}%
\end{minipage}

\vspace{3cm}


\textbf{\huge{}Real Options Valuation: A Dynamic Programming Approach}{\huge \par}

\vspace{1cm}


\selectlanguage{czech}%
\textbf{\huge{}Oceňování projektů metodou reálných opcí z pohledu dynamického progamování}{\huge \par}

\selectlanguage{american}%
\vspace{2cm}


{\large{}Master's Thesis}{\large \par}

}

\vfill{}

\begin{lyxlist}{MMMMMMMMM}
\begin{singlespace}
\item [{Author:}] \textbf{Filip Rolenec}
\item [{Supervisor:}] \textbf{Ing. Rudolf Kulhavý, DrSc.}
\end{singlespace}

\item [{Language~advisor:}] \textbf{Ing. Rudolf Kulhavý, DrSc.} 
\begin{singlespace}
\item [{Academic~year:}] 2020/2021\end{singlespace}

\end{lyxlist}
\newpage{}

~\newpage{}

~

\vfill{}


\begin{center}
\includepdf[pages={1}]{Images/zadaniMT.pdf}


\par\end{center}

\vfill{}


~\newpage{}

~

\vfill{}


\begin{center}
\includepdf[pages={2}]{Images/zadaniMT.pdf}
\par\end{center}

\vfill{}


~\newpage{}

\noindent \emph{\Large{}Acknowledgment:}{\Large \par}

\noindent I would like to thank my supervisor Ing. Rudolf Kulhavý, DrSc. for his professional guidance and all the advice given while creating this thesis. 

\vfill

\noindent \emph{\Large{}Author's declaration:}{\Large \par}

\noindent I declare that this Master's thesis is entirely
my own work and I have listed all the used sources in the bibliography.

\bigskip{}


\noindent Prague, \documentdate\hfill{}Filip Rolenec

\vspace{2cm}


\newpage{}

~\newpage{}

\selectlanguage{czech}%
\begin{onehalfspace}
\noindent \emph{Název práce:}

\noindent \textbf{Oceňování projektů metodou reálných opcí z pohledu dynamického progamování}
\end{onehalfspace}

\bigskip{}


\noindent \emph{Autor:} Filip Rolenec

\bigskip{}


\noindent \emph{Obor:} Matematické inženýrství 


\bigskip{}


\noindent \emph{Druh práce:} Diplomová práce

\bigskip{}


\noindent \emph{Vedoucí práce:} Ing. Rudolf Kulhavý, DrSc.


\bigskip{}


\noindent \emph{Abstrakt:} Investiční příležitosti jsou v současné době oceňovány pomocí řady algoritmů a metrik vzešlých z ekonomické teorie. Nejčastěji používaná metoda \textit{diskontovaných peněžních toků} (DCF) zohledňuje časovou hodnotu peněz a pro jednoduché projekty dává investorům velmi dobré odhady s minimálními požadavky na matematické znalosti. Složitější projekty, které v této práci chápeme jako projekty s vysokou mírou neurčitosti a existencí následných manažerských rozhodnutí, je možné oceňovat pomocí teorie \textit{reálných opcí} (ROA). Metoda ROA vychází z nedokonalé analogie oceňování finančních opcí a přiznává hodnotu možnostem změny projektového plánu. 

Tato práce má za cíl představit nový rámec pro oceňování investičních příležitostí, jejichž řízení je chápáno  jako stochastický rozhodovací problém. Tento rámec, umožňující využití desítek let výzkumu v oblasti stochastické rozhodovací teorie, pokrývá metody DCF a ROA, přičemž zjemňuje jejich předpoklady. Hlavní přínosy nového oceňovacího rámce jsou: možnost zodhlednění více zdrojů neurčitosti, modelování neurčitosti libovolnou distribucí, přímočaré začlenění bayesovského učení, modelování přístupu k riziku rozhodovacího subjektu a libovolný počet i druh povolených manažerských akcí. 

Nový rámec znatelně rozšiřuje třídu projektů ocenitelných s velkou přesností a lze ho chápat jako sjednocující zobecnění technik oceňování v podnikovém řízení. 


\bigskip{}


\noindent \emph{Klíčová slova:}   Analýza reálných opcí, Black-Scholes model, Diskontované peněžní toky, Dynamické programování, Energetika, Oceňování projektů, Stochastické řízení



\selectlanguage{american}%
\vfill{}
~

\begin{onehalfspace}
\noindent \emph{Title:}

\noindent \textbf{Real Options Valuation: A Dynamic Programming Approach}
\end{onehalfspace}

\bigskip{}


\noindent \emph{Author:} Filip Rolenec

\bigskip{}


\noindent \emph{Abstract:} The valuation of investment opportunities is currently done via metrics and algorithms formed by the economical theory. The majority of investors and companies still values projects with a method of \textit{discounted cash flows} (DCF), which takes into account the time value of money and gives solid results for simple projects with minimal requirement on mathematical skills. More complicated projects, which are in this thesis thought of as projects with a substantial degree of inner uncertainty and with an existence of further managerial decisions, can be valued by the \textit{real options analysis} (ROA). This method comes from an imperfect analogy to financial option valuation and it recognizes the value of the ability to change the course of a given project.  

This thesis presents a new valuation framework for projects, which are understood as problems of optimal stochastic decision control. This framework incorporates the DCF and ROA methods, simplifies the requested assumptions and allows for decades of research in the field of \textit{stochastic decision theory} (SDT) to be used. The main contributions of the new framework are: ability to incorporate multiple sources of uncertainty, usage of any distribution for modeling the uncertainty, ability to conveniently incorporate Bayesian learning, ability to model user's approach to risk and ability to model any type and scale of managerial actions.

The new framework significantly expands the class of projects that can be reasonably valued and it can be understood as a unification of project valuation in business management.


\bigskip{}


\noindent \emph{Keywords:} Black-Scholes model, Discounted cash flow, Dynamic programming, Power industry, Project valuation,  Real option analysis, Stochastic decision control

\newpage{}

~\newpage{}

\pagestyle{plain}

\tableofcontents{}

\newpage{}


\chapter{Introduction}
The ability to systematically and reliably value projects is the core of investment decision making. According to the economical theory presented by \cite{} \footnote{That guy from Duke university} profits of an investment reflect the value added to the participants on the market, who paid the money to enable the profits. The profits of the venture are understood as the ultimate measure of additional value that has been created. 

A good valuation technique enables companies to increase their profits and as \cite{BerDeM:09} (?)  says: the main and actually only goal of a manager is to increase the wealth of stakeholders. It is thus rather fortunate that, by the logic of \cite{} \footnote{Guy from duke}, in free market increasing this value coincides with the adding value to all interested participants on the market. One could thus extrapolate and say, that in free market, the goal of a manager is to improve lives of market participants. 

The current state of capital investment valuation techniques is very diverse. Majority of investors rely predominantly on the standard Net Present Value (NPV) technique, its generalization in a form of NPV with scenarios (sometimes called Decision Tree Analysis(DTA)) or NPV-derived metrics with some internal mostly fabricated parameters, such as Risk Adjusted Discount Rate (RADR) or Internal Rate of Return (IRR). \footnote{Create citations to these statements}

These valuation techniques are usually simple, resulting in a very limited scope of their application. Two main problems are that in their simplicity they do not address the problem of uncertainty or ability of further management of the projects in much detail, or in the case of uncertainty the argumentation is misleading \footnote{Risky FCFs should be discounted more...}.

In many articles and economical books one superior valuation technique, that recognizes the value of further managerial actions and also copes with the uncertainty in more complex way is cal Real Options Analysis (ROA). The valuation of projects is understood as analogy to valuation of financial options, which is elegantly handled by the Black-Sholes-Merton Nobel prize winning technique \cite{}. 

The value added by acknowledging of further management of projects (so called real options) with high uncertainty is significant. Articles \cite{} and \cite{} show, how the standard valuations tend to undervalue certain projects, which leads to unrealized opportunity of significant profits. 

 
<Talk about ROA, its advantages and usage in real life> \footnote{Do not talk about DTA in the complicated sense. }

<Talk about it not being applied in reality and its reasons> 

<Decide which problems will be solved in this thesis> 

<Talk about how this all is actually decision making and that it would be interesting to look at it as a SDT problem> 

<Say a brief history of SDT and how it fits naturally> 

<Say what is missing in SDT and what more does it offer, arbitrage vs utility thinking and Bayes> 

\vspace{5mm}

\ruletext{\textbf{The remaining text is left as inspiration}}
\vspace{5mm}

The current state of capital investment valuation techniques is a mess. Majority of investors still rely on the standard Net Present Value (NPV) technique or its slight generalizations in form of optimal/average/bad scenarios, risk adjusted discount rate (RADR) hurdles (usually set to an arbitrary percentage), internal rate of return (IRR) metric (which is essentially the same as RADR hurdles) and other metrics like,... ROIC, ENPV. 

All the listed generalizations try to cope with one of two main problems of NPV, which is inability to incorporate uncertainty (ENPV, scenario approach) or intra-investment comparison (IRR(?), ROIC). 

None of these valuation techniques acknowledges the managerial ability to take action and improve the course of an investment. ENPV can be interpreted is such way but that is abusing of its notation. 

The decision tree analysis (DTA) is the simplest approach for valuing an investment with acknowledging decision nodes as an inherit trait of an investment process. It should not be a surprise that being able to make a decision through the lifetime of an investment has value. Also, it is quite clear that the more uncertain the investment and its parts are, the more valuable the ability to act is. To value an ability to make a decision and change the path which the investment follows is not a complicated task. All it takes is to compare a value of a project with that ability and without it (both with DTA), and declare that the value of such "decision option" is the difference between the two. 

Many authors from the financial world \footnote{See \textit{this} and \textit{that}} use the term real option valuation when talking about this difference between DTA trees with or without some branches that represent the ability to make a decision and act upon it. I think that is rather unfortunate, since the terminology clashes with the real option valuation, which this thesis is about. 

The true real option analysis (ROA) is about being able to value investment options in the same way financial options are valued. The Black-Scholes-Merton option pricing model that is widely used in financial world is an exceptionally elegant valuation tool. All that it needs to know about financial option to valuate it is four parameters - the strike price and expiration date of an option itself, the volatility and current price of the underlying asset upon which the option is written. \footnote{probably some more assumptions}. This Nobel-Prize winning elegance led mathematical and financial experts to try to interpret investment decision making in terms of "real options", that can be valued in the same way the financial options are, by the BSM model. 

The attempts to interpret each of four important parameters of a financial option in terms of investment parameters are successful for simple cases (Dealership in BERK), however they fail for more complex ones. The ability to use real option valuation technique depends heavily on the ability to find a relevant company, stock or other publicly traded proxy variable to the examined investment. One finds plausible to construct a replicating portfolio for an investment in oil mining facility or a food production line, however this assumption is hard to believe for highly innovative products in new fields, such as software development or R\&D investments. 

The ROA valuation approach in investment decision making has cyclical nature. The first wave of the real ROA approach can be traced to ... who presented his ideas shortly after the initial publication about financial option pricing \cite{BlaSch:73}. Next wave comes with ... and finally the most recent publications trying to make practical use of real option analysis are \cite{} and \cite{}. 

Nearly all publications of real options published in the last <number> years talk about small penetrability of this approach to the actual usage by managers in large and small investment companies. The stated reasons are always the same,
\begin{itemize}
\item Vollert says that its complexity, but that is because he uses stochastic models, Ito lemma and computes PDEs, all the time. That has nothing to do with replicating portfolios and BSM model. 
\item Mr. Kulhavy says that the problem is in finding the replicating portfolio and even if you find it you have to persuade the manager to see it too. 
\item <Problem with adoption> 
\item <Another problem with adoption>
\end{itemize}


I believe that the current usage of ROA by investors makes sense. The actual ROA approach is based on finding a replicating portfolio that behaves in the same way as the investment. If a manager beliefs that he has found a replicating portfolio, then it does not make sense for him to value the project differently than the replicating portfolio. However, there is still the issue of finding such replicating portfolio. 

The usage of ROA in sense of different DTA trees is well posed. The ability to hold production in refinery in times of large oil prices can surely increase its value. In this sense the ROA has the biggest impact on the valuation in investments that are highly uncertain and in which there are actions that can alter the course of future cash flow. This also means that in the opposite case, when there is high degree of certainty about the execution and cash flow of the project, or if there are no actions to be taken, the ROA does not create additional value. 

The power of classic ROA is to seemly eliminate the probabilistic nature from the picture. This can be done by the power of all-wise market, that forbids the existence of arbitrage. If a tradeable  \footnote{This is a valid word, Cambridge dictionary say so... }replicating portfolio is found, then I should not care if I make my investment or if I use the money to buy the replicating portfolio. 

For the mathematicians from the field of stochastic decision making the problem of valuation is just another decision making under uncertainty. Define state  and action space, define rewards (free cash flow) in each epoch and get prior probability density as expected transition probability from one state to another upon undertaking certain action.

The difference between the SDT and ROA is that the former relies on the prior density functions, that are the core of Bayesian statistic, while the latter, coming from economics, relies on the power of the market and managers ability to find a replicating portfolio. 

In this thesis the state-of-the art theories of ROA valuation and SDT are presented. Their strengths and weaknesses are discussed and a hybrid approach from the cherry-picked parts of the corresponding theories is presented. 

The power of the new theory is shown on a class of problems called ... The current literature copes with them in much simpler way and their assumptions are much larger. My \footnote{Or the presented approach, should I avoid pronouns in the text? } approach also potentiates adoption in practical usage, as it puts the decision making manager in charge. The manager decides how to create the prior distributions, he is the one who needs to determine all the possible actions and scenarios that can happen. The algorithm that is presented in this thesis can and should be used in real world as a managerial tool to maximize the profits of divisions or companies as a whole. 


The goal to maximize wealth in financial world is approached in a really narrow matter. Money represents value, which in models decreases in time by a percentage given by some authority, most of the time central banks. In respected financial publications \cite{BerDeM:09}, \cite{} or \cite{}, there is no notion of utility. It seems like for financial institutions, it does not matter to get 1M in cash now or to gamble for 2M in a fair coin flip. On the other hand, in SDT,  the concept of utility is taken very seriously. Majority of people would prefer even a very small amount, such as 200k against a fair gamble between 0 and 2M. This is due to the concave utility function people tend to have when very high amounts are discussed and the question is more about what would make them happier. 

Maximization of wealth either in the sense of investment company or individual is natural. Almost everybody would agree that to have more wealth is better than have less. Better investment decisions mean higher accumulation of wealth, which together with assumption of free market results in an increase of utility of each participant in the economy \footnote{Find that reference... Duke university lectures... }. In other words, when a company makes higher profits it should mean that the part of the population that participated in the wealth creation should be happier. 

\ruletext{}


%\addcontentsline{toc}{chapter}{Introduction}



%\addcontentsline{toc}{chapter}{Preliminaries}

\pagestyle{headings}




\chapter{Preliminaries}
\ruletext{Introduction to preliminaries}

To properly understand a mathematical text it is important to first define the used notions and symbolism. Since this thesis is based on many different authors, from both financial and mathematical world, a short unifying overview of the used theory is important. 

The notation used in this thesis comes predominantly from the most influential authors in the respective fields of study: 
\begin{itemize}
	\item general economy \cite{BerDeM:09};
	\item real options \cite{Gut:09};
	\item stochastic decision theory \cite{BacChi:19}.
\end{itemize}

 The pure mathematical symbolism comes from the author's studying experience at FNSPE CTU and its applicability is proven in his previous works \cite{Rol:18} and \cite{Rol:19}. 
\footnote{Filip == Author or Filip == I/Me} 

\ruletext{}
\section{Used mathematical symbolism}
\ruletext{Sets, random variables, what do I mean by 'probability'}

In the whole thesis, bold capital letters, such as $\mathbf{X}$, represent a set of all elements $x \in \mathbf{X}$ as in \cite{Rol:18}. The cardinality of a set $\mathbf{X}$ is denoted with two vertical lines as $|\mathbf{X}|$. Random variables, understood in a sense of the standard Kolmogorov's probability theory \cite{Kol:60}\footnote{Does this citation make sense? }, are represented with a tilde above the variable, i.e. $\tilde{x}$. Realizations of random variables are denoted by the same letters as the random variable without the tilde, i.e. $x$. 

\begin{definition}(Probability)
	Let $\tilde{x}$ be a random discrete variable. Then $P(x)$ denotes a probability that the realization of $\tilde{x}=x$. Similarly if $\tilde{x}$ is a continuous random variable, then $p(x)$ denotes a probability density of the realization $\tilde{x}=x$. 
\end{definition}
\begin{remark}
	To rigorously unify the notation and simplify the formulas a Radon-Nikodým (RN) density \cite{Rao:87a} is introduced  with the notation $p(x)$ and the name ``probability density``. The dominating measure of this RN density is either the counting measure (in discrete case) or a the Lebesgue measure (in continuous case). The notation $P(X)$ is reserved only for the cases when the discreteness of the argument needs to be emphasized. 
\end{remark}

The last general definition is the definition of well known concept of conditional probability \cite{Jay:03}. 
\begin{definition}(Conditional probability)
	Let, depending on the context, symbol $p(x|y)$ represents either the conditional probability on discrete variables or the conditional probability density on continuous variables. Then the $p(x|y)$ is defined as:
	\begin{equation}\label{eq:condP}
	p(x|y)=\frac{p(x,y)}{p(y)},
	\end{equation} where $p(x,y)$ is a joint probability density of $x$ and $y$. 
\end{definition}

\begin{remark}
	The definition of conditional probability expressed by the equation (\ref{eq:condP}) corresponds with the classic definitions of the conditional probability and conditional probability density in both the discrete and continuous case. 
\end{remark}

<Probably some other definitions that will be needed in the following chapters> 

\ruletext{}

\section{General economics}
\ruletext{Introduction and basic financial concepts. }

This thesis is built on two main theoretical pillars, the theory of corporate finance \cite{BerDeM:09} and stochastic decision theory (SDT) \cite{BacChi:19}. A basic review of corporate finance terminology and procedures is presented in this section with a focus on project valuation techniques. 


\begin{definition}[Project]
	A project is defined as a piece of planned work or an activity that is finished over a period of time and intended to achieve a particular purpose, mainly a wealth increase of a company or an individual. \footnote{First part comes from Cambridge dictionary. Is that ok just to cite it? }
\end{definition}

\begin{definition}[Value]
	The amount of money that can be received for something. \footnote{Again cambridge dictionary...} \footnote{This definition is added to say that by value in economics we mean money that we can obtain from the asset.}
\end{definition}

A value of a project is naturally a function of realized elementary monetary transactions within the project and the potential selling price of remaining assets. To track and model each transaction of a project in detail is in principle possible, but such approach would be way too complex for practical usage. Furthermore, its benefits would most likely not be significant enough to defend the extra effort of decision makers. 


For purposes of project valuation an aggregation of elementary monetary transactions - a concept of cash flow (CF) and free cash flow (FCF) are used in the world of corporate finance. 

\begin{definition}(Cash flow)
	Cash flow is the net amount of cash and cash-equivalents being transferred into and out of a business (project).  \footnote{Investopedia, economical books do not define it. }
	
\end{definition}

\begin{definition}(Free cash flow)
	The incremental effect of a project on the firm’s available cash is the project’s free cash flow \cite{BerDeM:09}: 
	\begin{equation}
		FCF = OCF - Capital Expenditures, 
	\end{equation}
	where $OCF$ is the operating cash flow and $CE$ are the capital expenditures. 
\end{definition}


Cash flows are in their detail nature discrete, each transaction within the project changes the global cash flow. The moments in which transactions legally take place could be taken as individual time instants. 

However, it is easy to imagine understanding the cash flow as a continuous stream of money per time. By the nature of corporate management, one could also expect, that in majority of non-extreme applications, this would not result in a major distortion of cash flow reality. \footnote{Should I discuss here more. I mean that corporate management does not care about each transaction in each store, it cares about daily or even monthly revenues.}

All of this is true also for free cash flow. 

In this thesis we will further work only with the FCF, so from now on, the term \textit{cash flow} will only mean free cash flow. \footnote{Maybe confusing, consider to define only FCF and call it cash flow...}


\ruletext{}

\subsection{Standard valuation metrics}
\ruletext{NPV, DTA, IRR, WACC and others}

Cash flows capture information about value added to a project in given periods. Due to time value of money and different lifespans of projects, one has to come up with algorithms for their consistent and systematic valuation, according to their cash flows. 

Valuation techniques are attempts to aggregate cash flow vectors in one meaningful number to enable decision makers to choose the best investment. 

\paragraph{Net resent value}
First valuation technique, net present value, is arguably the most used valuation technique in capital budgeting \cite{} \footnote{Is this a strong enough statement that I need to cite somebody?}. Its computation is simple and it can be described as a sum of cash flows discounted for the time value of money:

\begin{equation}
NPV = \sum_{t \in \mathbf{T}} \frac{C_t}{r^t}, 
\end{equation}
where $\mathbf{T} = \{0,1,...,|\mathbf{T}|\}$ is a set of time periods in which the cash flows $C_t$ are obtained. These periods are usually years or months, but they can effectively have any granularity the decision maker wants them to. Discounting factor $r$ expresses the time value of money and is usually derived from the current risk-free interest rate given by the central bank of a nation. \footnote{The discussion about negative interest rates and thus r<1  and also the correct discounting rate is left to my valuation in chapter 3.}

The NPV valuation technique is simple to use, assuming we know the discount rate, which is  constant through the project's duration, and free cash flows, that are assumed to be certain. \footnote{Should I put an example here or would that be too trivial? Cash flow is [-400, 100,100,200,200], interest rate 5\% -> NPV is... }

A more advanced approach that acknowledges the variability in both cash flows and risk-free interest rate is called expected NPV(ENPV) :\footnote{Seems like literature does not use this and I made it up. In the eyes of economics, the cash flows seem to be expected values all the times, the distribution is not considered. } \footnote{Also there is ENPV as "Expanded NPV" NPV+options value used by Vollert, Pindyck and others. }
\begin{equation}\label{eq:NPV}
	ENPV = E\left[\sum_{t \in \mathbf{T}} \frac{\tilde{C_t}}{\tilde{r_t}^t} \right],
\end{equation}
where both cash flow and interest rate distributions are  expected to be known. 

\paragraph{Decision tree analysis}
The simplest valuation technique that acknowledges the importance of further management of investments is called decision tree analysis (DTA) \cite{Vol:03}. In addition to time value discounting of cash flows it offers a framework that can incorporate active management of a project, potentially increasing its overall profits. 

The ability to make actions in projects is sometimes interpreted as having \textit{Real Options} \cite {Gue:17} or \cite{Vol:03}.\footnote{Check if Vollert uses ROA as a lens only...  } This confusing terminology might result in misunderstandings. That is why it needs to be emphasized that, in this thesis, valuation that recognizes the ability of a manager to act but ignores the \textit{law of one price} will be called DTA. 


\begin{definition}[Law of one price]
		<Definition of Law of one price> 
\end{definition}

The decision tree analysis is usually used only for valuation of projects with very simple scenarios. However, its structure could be potentially used for much more complex problems. 

The criticism of DTA coming from Vollert \cite{Vol:03} and others \cite{} is that DTA uses a single discount rate for different branches of the project. This is contradictory to the standard rule in the economics that riskier projects should be discounted more \cite{}. 

However, this criticism could be countered with upgraded DTA in which one would allow variable discount rates in different branches rather easily. Furthermore, both Vollert \cite{Vol:03} and  ... \cite{} do not address the problem of the constant discounting rates and use them in their final valuation algorithms as well.  \footnote{Needs to be confirmed}

The discussion about risk and its role in a valuation algorithm is deferred to the section \ref{}. 

\paragraph{Internal rate of return}
The internal rate of return serves usually as a basic threshold for enterprises entering new projects. Each company would have their own internal threshold of IRR, based on their confidence in ability to make more or less returns on their investments. A startup would most likely have an IRR higher than a long time established bank. 

\begin{definition}[IRR]
	The internal rate of return is the interest rate that sets the net present value of the cash flows equal to zero \cite{BerDeM:09}. This means that IRR for cash flows $C_t$ needs to satisfy the following equation:
	\begin{equation}\label{eq:IRR}
		0=\sum_{t=0}^{T}\frac{C_t}{(1+IRR)^t}
	\end{equation}
\end{definition}

The problems with IRR are that additional assumptions on cash flow vector have to be satisfied so that there exists only one unambiguous result of the equation \ref{eq:IRR}. \footnote{Or maybe there are no clear assumptions, but I know that the result of the equation might not exist or it might have multiple results.}

\paragraph{Weighted average cost of capital}

\vspace{5mm}

\textbf{<This paragraph is not true, needs to be redone. The WACC is a combination of a premium that investors want in order to hold the shares of the company and a rate for which the company can borrow money. The risk free rate does not play any direct role in WACC. >}
 
The term time value of money represent the truth that the value of money today is not the same as next year. Due to the modern economical theory, inflation is a pursued phenomenon, keeping the economy running. 

The existence of a risk-free interest rate in an economy is assumed and it is usually determined by the rates of bonds issued by the central banks of given nations. 

In capital budgeting the time value of money has a close connection to cost of capital. The cost of capital can have two forms, based on the money source for your investment. In the first case, you have some cash reserves and by investing in a project the only cost of capital is that you forego the opportunity to invest in bonds with risk-free rate of return, "paying" the opportunity cost. In second case, if company's funds are not sufficient, you need to borrow money on the market for an interest rate, which results in additional "cost" of capital. 

The interest rates in second case are naturally higher, since lenders carry additional risk of borrower's default. 

The term weighted average cost of capital combines the costs of capital coming from the two sources, further incorporating the notion of corporate tax reliefs. 

\begin{definition}[WACC]
The firm's effective after-tax cost of capital is called the weighted-average cost of capital (WACC): 
\begin{equation}
	WACC = \frac{E}{E+D}\cdot r_E + \frac{D}{E+D}\cdot r_D (1-\tau_C), 
\end{equation}
where E is the value of equity, D is the value of debt, $r_E$ the equity cost of capital, $r_D$ the debt cost of capital and $\tau_C$ is the corporate tax rate.
\end{definition}


\ruletext{}

\section{Real option analysis}\label{sec:ROA}

\ruletext{What is ROA, introduction and hint of larger future discussion in the next chapter}
	
	
An option in financial world means having a right to buy (or sell) an asset in future for a fixed price (strike price) \cite{BerDeM:09}. Option trading has origins in commodity markets (for example corn or oil), where participants want to in some sense insure themselves against the negative movement of a price on the market. Options that are being traded today on the derivative market span almost every tradeable asset that can be though of \footnote{Find some citation or do not use this sentence.}. 

The value of an option naturally depends on its time to maturity, current price of the asset and a strike price. A proper valuation method for European options with no dividends came with the Black-Scholes-Merton model \cite{BlaSch:73}, which in addition requires only the volatility of the underlying asset and the following assumptions: 
\begin{itemize}
	\item Effective markets ...
	\item Log-normal distribution of the asset price
	\item There are no transaction costs in buying the option
	\item The risk free rate is known and constant. 
\end{itemize}


This established and well received technique for financial option valuation spawned the idea of real option analysis. The option to buy an asset for a given price is similar to the ability to buy an expected future cash flow, i.e. invest in a project. 

<Origins of real options> The first economist, pioneer of the term \textit{Real option analysis}, ... ... treats investments as a complete analogy of trading with options. To be able to delay an investment has a value and..... 

The usage of the phrase real option analysis in literature is rather fuzzy. It is used by many authors such as \cite{BerDeM:09}, \cite{Gut:09} and \cite{Gue:17}, however their usage of the term differs. Three different usage classes of the term real option analysis were identified by the author. They differ by the level of analogy to the valuation of financial options. 

\paragraph{Complete analogy}
First, there is a class of complete analogy. All five parameters of financial options needed for their valuation with BSM model are identified with the parameters of an investment opportunity. An example of a valuation of a car dealership can be found in \cite{BerDeM:09}\footnote{Should I reference page numbers? Will anybody actually look up the example? } where the following identification is made:

\begin{table}[H]
	\begin{footnotesize}
		
		\centering
		\renewcommand{\arraystretch}{1,2}
		\label{Tab:BSModel}
			\begin{tabular}{|l |r|}
			\hline	
			Financial option& Real option \\ \hline
			Stock price& Current market value of asset \\ \hline
			Strike price& Upfront investment required	\\ \hline
			Expiration date& Final decision date \\ \hline
			Risk-free rate& Risk-free rate\\ \hline
			Volatility of stock & Volatility of asset value \\ \hline
			Dividend & FCF lost from delay \\ \hline
			
		\end{tabular}
		\caption{Identification of parameters for real options with respect to the financial option \cite{BerDeM:09}. }
	\end{footnotesize}
\end{table}

Another example can be found in \cite{Que:10} where a telecommunication company is being valued by the complete analogy valuation technique. 

This class of authors focuses on the clear analogy and thus the acknowledged scope of possible manager's actions is limited basically only to timing options. The only decision is to invest to a project now or later.


\paragraph{Partial analogy}

The second class of authors uses only the core property of the financial analogy and that is the law-of-one-price. With the help of this assumption, the authors, eg. \cite{Gut:09} usually derive risk-neutral probabilities which are then used for modeling of some internal variable of the cash flow functions. 

This class of authors is the most numerous and most mathematically rigorous. The core of publications in this class is usually in solving stochastic differential equations, eg. \cite{Vol:03} whereas the role of the assumption about law-of-one-price is used mainly as the ground for obtaining one of the missing parameters of the stochastic model. 

\paragraph{No analogy}

Third class of authors does not use the law-of-one-price and is thus the farthest away from the original idea of ....\footnote{The pioneer name}. This class of authors, i.e. \cite{Kas:04} and \cite{Gue:17}, understands the term real option analysis as a useful lens for looking at the project valuation. They accentuate the value of further managerial decision, but the valuation structure and algorithms do not differ from the DTA approach as defined earlier. 

Thus, this class of authors is declared as a misuse of terminology and not further considered. 

\bigskip

In the next part of the thesis, namely \ref{} the core message behind the term real option analysis will be thoroughly discussed. 

\ruletext{}

\section{Statistical decision theory}
\ruletext{Standard SDT as a framework, states, actions, inputs, outputs, rewards, probability distributions}

The second pillar upon which this thesis stands is the statistical decision theory (SDT). An area of applied mathematics that formalizes and studies optimal decision making of agents. As decision making in its broadest sense encapsulates a vast amount of human behavior, the class of problems it is able to solve is quite large. 

The SDT's main focus is to determine the optimal strategy (a sequence of decisions) to act upon, generally in dynamic and uncertain environment. A classical structure of a decision making problem consists of five building blocks

\begin{itemize}
	\item Set of time epochs - $\mathbf{T}$;
	\item Set of environment states in those epochs - $\mathbf{S}$;\footnote{Possibly different $S_t$ in different times.}
	\item Set of actions in those states - $\mathbf{A}$;
	\item Reward function of transition from one state to another - $r(s_t|a_t,s_{t-1})$;
	\item Transition probabilities governing the transitions from one state to another $p(s_t|a_t,s_{t-1})$.
\end{itemize}

The set of time epochs, states, actions is usually known, defined by the structure of the decision problem that is being solved. Reward and transition functions tend to be unknown in solving these problems and they need to be often somehow estimated. 

Usually, the biggest task in SDT is to correctly approach the uncertainty about transition probabilities between the different states of a project. There are two approaches to parameter estimation in statistics, classical approach and a Bayesian approach. Since the Bayesian approach seems to fit the format of decision making better - allowing for smooth updating on newly observed data - it is used in this thesis. 

The goal of SDT is to find the optimal strategy - sequence of actions. The optimality of such strategy is defined as it having the maximal expected cumulative reward among all eligible strategies 

\begin{equation}
	\pi^*=\argmax_{\pi \in \mathbf{\Pi}} E\left[\sum_{t\in \mathbf{T}} r(s_t|a_t,s_{t-1})|\pi\right].
\end{equation}

This maximization can be in total absolute values (in finite or discounted cases) or per time period (mostly in infinite non-discount cases). Due to the economic nature of this thesis we will focus on the total cumulative reward of a finite process (?). 

\subsection{Dynamic programming}
To maximize over all possible strategies by computing the expected cumulative reward for each one of them is a very demanding task even for low-dimensional decision problems. 

Thus, a clever idea of backward induction called dynamic programming is used. A function, called the value function is defined on the set of all possible states $\mathbf{S}$. This function represents the expected cumulative reward to be obtained from the given state onwards. The idea of backward induction is based on the truth that a sequence of actions is optimal if and only if the last action is optimal. 

This clever computation of value functions from the problem horizon backwards through all the possible states of the problem decreases the complexity from exponential to polynomial. Instead of maximizing over $|\mathbf{A}|^{|\mathbf{S|^{\mathbf{|T|}}}}$ possible strategies at once, one needs to compute significantly less demanding complexity of $|\mathbf{A}|\cdot|\mathbf{T}|\cdot{|\mathbf{S}|}$. \footnote{Check this}

The formula representing the backward induction is called the Bellman equation: 

\begin{equation}
	V(s_{t-1}) = \sum_{s_t \in \mathbf{S_t}} p(s_t|a_t, s_{t-1}) [r(s_t|a_t, s_{t-1})+V(s_t)].
\end{equation}

By defining the value function on the horizon, we can compute value functions of states with lower and lower time indexes, until we get to the time 0, which represents the present. Not only that we have the expected value of the optimal decision making, but we have also derived the optimal strategy for every possible path through the state space. 

The backward induction reduces the computation complexity significantly. However, for even a moderate-dimensional decision problems, the number of computations is still extremely large. 

The problem of computational complexity of dynamic programming is called "three curses of dimensionality" \cite{Pow:11} and various solutions have been proposed. These solutions are as a group referenced as approximate dynamic programming. 


\subsection{Approximate dynamic programming}

The computational complexity of dynamic programming for moderate and high-dimensional decision making problems is so demanding that results cannot be obtained in a reasonable amount of time. 

The response to this problem comes in a form of approximate dynamic programming, a section of decision making under uncertainty, that is represented by a number of algorithms that are trying to obtain quasi-optimal strategies with more reasonable demand for computation power. 

There are many different algorithms, that try to obtain approximate results of the precise dynamic programming represented by the bellman equation. In this thesis the ADP algorithm called <Q-learning, SARSA...> is used because of its high performance in ..., while being still relatively easy to implement. A longer discussion of its choice is left to its corresponding chapter \ref{}. 

\paragraph{<Q-Learning, SARSA,..>}
<Detailed description of the chosen ADP algorithm> 


\subsection{Bayesian statistics}

The field of mathematical statistics can be divided into two branches, classical (also called frequentist) and Bayesian. The philosophies of each one are fundamentally different, however in principle, they can serve for revealing new truths of the measured data in a similar fashion. 

Mathematical statistics is a very broad topic, not possible to summarize it in one paragraph. The use of Bayesian statistics in this thesis is only as a tool, no broader discussions about the internal philosophy of different approaches are presented.

In general, statistical theory is used to determine a distribution from which the observed data come from. In majority of cases, it is assumed that the data are realizations of a random variable with a distribution from some parameterized class - normal, log-normal, poisson, etc. The goal is then to determine, with some level of confidence, the parameters that fit the observed data in some sense the best. \footnote{Large simplification, statistics can be used in many different ways.} 

The main difference between the Bayesian and classical statistics is how the parameters of a distribution are perceived by the statistician. In the classical theory, it is assumed that observed data come from some distribution with some firm but unknown parameters $\Theta$. In contrast, the Bayesian view on the parameters is such that they are perceived as random variables $\tilde{\Theta}$. 

This terminology twist can be a source of initial confusion for frequentist statisticians, but it allows a simple and elegant update of parameter estimates with the Bayes formula.

\begin{equation}
	p(\Theta|d)=\frac{p(d|\Theta)p(\Theta)}{p(d)}, 
\end{equation}
where $\Theta$ is generally a multivariate parameter and $d$ are observed data. \footnote{The p(d) in denominator needs to be rewritten as integral if this formula is really to be used.}

The interpretation of Bayes formula, is that the distribution of parameter $p(\Theta)$ called the prior distribution, is updated for the newly observed data $d$, providing new, posterior,  distribution $p(\Theta|d)$. 

This update can be understood as learning about the "true value" of a parameter, which is very useful structure for dynamic decision problems. 

Since the Bayesian theory tells us only how to update an already existing distribution, a prior distribution needs to be given, even though no data were measured yet. 

This problem is in Bayesian statistics understood as an advantage, since one can use his knowledge about the problem that is being solved and incorporate it to the prior distribution, which is then updated on the measured data. 

The task of consistent creation of prior distribution is a complicated topic and can be found in more detail in \cite{Ber:85}. Furthermore the prior information always exists, as Peterka \cite{Pet:81} puts it: "No prior information is a fallacy: an ignorant has no problems to solve".  


\subsection{Utility}
The concept of utility instead of monetary or other globally measurable gain comes in when the gains are valued non-linearly. 

 Multiple studies show \footnote{Find citations (?) or omit this formulation}, that the majority of people are risk-averse, meaning that the value of uncertain monetary gain is not equal to its expected value. 

One of the simplest example to demonstrate the usage of utility is given by \cite{BacChi:19}. Imagine an individual is given a choice, either to get 500\$ right away or to gamble for 1000\$ in a fair coin toss. A rational decision maker driven only by the expected value of his actions would be indifferent to the two choices. However, the majority of people tend to take the certain amount instead of gambling. 

This example can be reformulated as follows: How much money would the decision maker need to obtain for certain so that he would be indifferent to gamble for a 1000\$. In other words, how much the risk-averse person values that gamble. 

The non-linearity of utility obtained from large amounts of money is only more understandable for very large sums of money. There is a little difference for an average human in obtaining 10M USD and 20M USD. The change in the person's life will be almost the same and presumably positive. However one result is certain and the other one has only a probability of 1/2. 

Another interesting example of the risk-aversion of people is the famous St. Petersburg paradox first formulated by Bernoulli in 1738, \cite{Ber:54}. A risk-neutral \footnote{Define risk-neutral (?)} decision maker would be willing to pay any amount of money to be able to play a game defined by the paradox. However it is shown that people seldom value the game more than 25 USD, which corresponds to a case that the initiator of the bet does not have an infinite amount of money, rather only 16,5M USD \cite{}. \footnote{This is from wikipedia, find more cool sources. Interesting, but does not have to be in the thesis}

Regarding to utility there is also an interesting asymmetry in human psychology about obtaining gains and incurring losses. The graphical expression of this asymmetry can be found in \cite{BacChi:19}. \footnote{Put the picture here, or cite the exact page?} 

The utility function of each decision maker is different and an approximation of its shape can be obtained by an algorithm based on a questionnaire, which also ensures the consistency of responses of a given individual. 


\chapter{Project valuation as stochastic decision problem}
<Talk about how projects are valued now in economy with semi-mathematical concepts, say that SDT fits the problem very well. Say that prior the implementation of valuation as SDP, several key non-trivial parameters and concepts need to be discussed.> 

The current process of project valuation is done by the economical algorithms with different attributes. They differ in computational complexity, requirements on mathematical knowledge of the managers and ability to incorporate further decision making or uncertainty into the valuation.

These algorithms, that help to generate a decision making basis for managers (NPV, IRR, ROA,...) are somehow artificial. They are based on very strong assumptions and they tend to simplify and compromise in various aspects of handling uncertainty, time value of money and the structure of a project. 

Due to the many shortcuts, simplifications and hard assumptions that the economical theory makes, it is only sensible to try to formulate investing (and its further management) as a stochastic decision problem, which allows for much broader description with less assumptions. 

Before describing the new valuation technique, that intends to be a generalization of the current economical algorithms, several key features of the economical valuation techniques need to be discussed. 

First is the core of ROA, which is by many authors (\cite{} \cite{}, \cite{})described as the most advanced valuation technique in use. In the first section of this chapter, we will look at the main message that the ROA actually tries to communicate, so that we can use it in the SDT-fashioned valuation technique. 


Second is the approach to risk. In the second section of this chapter, the approach to risk of economical valuation techniques is discussed. I believe that it does not stay on a firm ground and that it uses shortcuts which effectively mix the role of uncertainty and time value of money. 

Third is the discussion about the time value of money, which is in economics usually understood as discounting the future FCF by a constant rate. The approach of economical books has a large assumption that investors can borrow for the same rates as they can make risk-free investments , which is not the reality for most investors \cite{}. Also, as mentioned before, the future cash discounting is being misused to compensate for uncertain future FCFs, because of a belief that more riskier FCFs should be discounted more. 

This chapter culminates with the actual SDT-fashioned valuation technique, that respects both SDT theory and the key concepts of valuation from economical theory. 

\section{The core of ROA}

<Say, what actually ROA is in its core, estimate of expected mean of the price. This is the strategy that is taken as the most advanced in Economics and that managers do not have enough math skills to use it> 
The Real Option Analysis is not clearly defined project valuation framework. Coming from non-optimal analogy with valuation of financial options, namely the BSM model, it brings a new way of looking at the valuation of a project. 

To be able to talk about the real option analysis, we should first talk about the essence of the BSM financial option valuation model. 

When the BSM model is deconstructed, it can be seen that it only describes the price of the underlying asset by one specific distribution and that the final valuation is the expected profit of the option holder. 

The BSM model expects the logarithm of the underlying asset's price to follow a wiener process, a limit of random walk. This means that in each given time instant the asset price is expected to be distributed log-normally, i.e. coming from the class of log-normal distributions, which has the following probability density: 

\begin{equation}
p(x) = \frac{1}{x\sigma\sqrt{2\pi}}exp\left(-\frac{(ln(x)-\mu)^2}{2\sigma^2}\right)
\end{equation}
where $\sigma>0$, $\mu \in \mathbb{R}$ are parameters of the distribution and $x \in (0,+\infty)$ is a variable. 

The first discussed assumption of ROA thus means that, given the current price of an asset $x$ the distribution of price in any given future time $t$ can be described by only two parameters $\sigma$ and $\mu$. 

The second assumption for BSM model is rather simple. The variation of the asset price is assumed to be known. Its actual derivation is usually obtained from the abundant historical data about the asset price as can be seen in \cite{Gut:09}. 

The next assumption of the BSM model is in my opinion the core of the whole ROA approach and it is certainly worth to be incorporated into the SDT framework. This assumption is about effective markets and the law of one price. The law of one price says, that there cannot exist an arbitrage, a way to get more than the risk-free interest rate with no additional risk. 

This assumption effectively results in obtaining the second parameter in modeling the price of the underlying asset as log-normally distributed, $\mu$.  Due to the non-existence of arbitrage, the value of option, its replicating portfolio and given amount of bonds have the same expected returns,the risk-free interest rate. \footnote{Already confirmed on a binomial model, further, needs to be confirmed on the continuous case also. }

The last assumption about risk-free rate being constant is not of major interest, it merely serves as a reminder of the time-value of money, which is taken in the financial world very seriously. 

To conclude, the origins of ROA in BSM model are giving us the distribution of the future price in any given time through two variables, $\sigma$ obtained from the past observations of the price movement \footnote{Time scale adjusted} and $\mu$ from the assumption about arbitrage-free world. \footnote{Arbitrage free world gives us the $\mu$ when there is a replicating portfolio, it cannot be used all the time... }

\section{Approach to risk}
<Talk about how risk is understood in economics, and how SDT has a really nice framework for that> 

The usage of the term risk varies widely in the literature. In the spoken English the meaning of risk is the possibility of something bad happening \footnote{Cambridge dictionary}. In parts of SDT, namely \cite{DeG:04}, the meaning of risk means the minimal expected loss. Business administration \footnote{Podnikova ekonomika} \cite{Kni:21} understands risk as uncertainty that cannot be modeled. 

In economical books \cite{BerDeM:09} or \cite{} risk is understood as uncertainty of  returns on the investment. This uncertainty is presented as volatility - standard deviation: 
\begin{equation}
risk = \sqrt{E[\tilde{R}^2]-E[\tilde{R}])^2}, 
\end{equation}
where $\tilde{R}$ is a random variable representing the uncertain return of an investment. This definition fits the narrative of this thesis and will be used from now on. 

Historical records of different standardized investment opportunities - World stocks, small stocks and S\&P 500 - show a clear positive correlation between return of an investment and its volatility \cite{BerDeM:09}. In spite of the small sample, these investment opportunities cover a majority of the classical financial investments of non-derivative market. 

The conclusion of this observation is that investors are risk-averse and the more volatile an investment is, the more returns they require. If all investors would be risk-averse, the correlation between the volatility and returns of different asset types would be statistically improbable. 

The concept of risk-averse investors is very similar to the findings of SDT about risk-averse decision makers \cite{BacChi:19}, who in the same fashion prefer certain gains over uncertain, despite their nominal value being lower than the expected value. Both economical theory and SDT observe this type of human behavior, however SDT addresses it formally using utility theory. Instead of speculations about the "true" relationship between risk and returns, the SDT formalizes individual preferences of decision makers with a utility function. The goal of a decision maker then not to maximize the expected nominal value of his decisions, but his expected utility. 

The superior approach of SDT to human risk aversion will be further used in the proposed valuation technique of this thesis. 

\subsection{Risk-premiums}
Another important concept in the world of investment that concerns risk is the so called market risk premium. Similar to the observations of the relationship between returns and risk, historical records also reveal a relationship between returns of investments and their correlation with the overall market \footnote{The term overall market is usually aproximated by a wide stock index, \cite{BerDeM:09} uses S\&P500}. Positively correlated investment opportunities tend to have higher returns (the investors require a market-risk premiums) than those with no, or negative correlation. 

The conclusion of this observation is that the negative correlation of an asset to the overall market has value for the investors as a tool fo hedging. Historical data show, that investors are satisfied with holding low-return investments, as long as they perform well in the time of crisis. 

To cover this behavior fully by SDT, one needs to make the utility function two dimensional: 

\begin{equation}
U(r, c_{m})
\end{equation}
where $r$ is a nominal reward and $c_{m}$ is a correlation of that reward with the market.

When computing the expected utility of an uncertain reward $\tilde{r}$, the individual realizations $r$ do not have different correlations with the market, which makes the computation of maxima easier. 

Furthermore, due to the nature of project investment, there are usually only few different branches of the project where the cash flows have different correlation to the market. This is why we can introduce branch-specific one-dimensional utility functions, denoted with subscripts: 
\begin{equation}
U_b(r),  b \in \mathbf{B}
\end{equation}
where $b$ represents a single branch of a project and $\mathbf{B}$ is a set of all branches with different correlations of FCF flows with the overall market. 

\section{Time value of money}
<Talk about how simply does the economical theory approach this problem and offer the new solution> 

The value of money changes in time and it is determined by the supply and demand curve as any other asset. \footnote{Is asset a good word?} It might be confusing to talk about "value" of money, since we are used to measure the value of assets in money, but that is effectively a shortcut in human thinking. 

The supply side of the "money market" is a national monopoly usually held by central banks. Due to the belief of the majority of them in the theory of ... they try to keep the supply such that the inflation rate is around $2\%$ \cite{}. The existence of a monopoly with potentially unlimited supply and a strictly positive inflation philosophy results in a decrease of money value in time. 

When talking about the time value of money two rates are important. 

First is the risk-free rate, which says the rate that the investor is able to get with no risk. This rate is an approximation, no-risk investment does not occur in reality. Economical books determine this rate from the observable returns on government issued bonds. The risk-free rate determines the minimal appreciation of already held money. It is expected to be positive, but as the recent unprecedented events show it can also be negative. \footnote{Negative interest rates were presented by the central banks of: Japan(xY bond, -0.5\%, 2018), Germany(...), Australia(...)}

The second important interest rate is the one for which investor can borrow money on the market. This rate is a function of many variables, such as the amount of borrowed money, the credibility and valuation of the investor, and also risk of the project. With the assumption of risk-neutral creditors and no fixed costs associated with the process of lending money, the only relevant factor for creditors to obtain a given expected return is the debtor's probability of default. 

The rate at which a project's investor is able to borrow may vary significantly. A large bank has only a small risk of default compared to a newly established tech startup with no assets that serve as a guarantee. In the first case, the debtors probability of default is significantly smaller and thus the creditor requires lower interest rates. This rate can be with the help of economical theory substituted by the WACC. 

The usual strategy for coping with time value of money in economics is by discounting the future value by an exponentially growing rate $(1+r)^t$, effectively "exchanging" the future money for the money today. The problems with this discounting is that the rate is expected to be constant and the same for borrowing and risk-free investing. 

In this section I embrace the idea of "exchanging" money in time and I try to solve the two problems listed above. I argue that the effective discount rate for valuation of a given FCF vector is individual for each company and it is between the two aforementioned rates, where the closeness to each one of them is based on the level of self financing of that FCF vector. 

The key idea of valuation of FCF vector lays in the indifference. I argue that given a certain positive \footnote{so far} FCF vector, there exists an amount of money, that an investor should be indifferent to obtaining now. This is effectively the "fair-price" of such a FCF, which is effectively a project. 

This feeling of indifference does not embrace another of human decision making flaws, where they internally assign uncertainty to money rewards in the future. All the cash flows in the FCF vector are certain. 

I define the Net Present Value (NPV) of a FCF vector as a volume of money $x$ that is such that I am indifferent to having $x$ now, or the rights to FCF vector. This is not an abuse of notation since the rate in NPV is not strictly defined, and as we will see, the idea of indifference will introduce an "implicit" interest rate. The idea of indifference is effectively only proper way to derive the "correct" discount rate for NPV, based on logic and more detailed information about the investor. 

The NPV of a given FCF vector is a function of risk-free interest rate, amount of free money the company has for investments and the rate with which is the company able ot borrow. The idea is that the investor has two options, either to buy the FCF vector for $x$, generally partially with borrowed money or invest the free money in the risk-free investment. The $x$ has to be such, that no matter the initial action, after the returns from FCF end, the investor has the same amount of money. 


Due to the non-linearity of the implicit equation for NPV for given FCF vector, the value $x$ is derived numerically by the following algorithm: 
\begin{algorithm}
	<The algorithm I have in python now> 
\end{algorithm}

The effective discount rate, can be computed by the following implicit equation: 

\begin{equation}
NPV = \sum_{t \in \mathbf{T}} \frac{C_t}{r^t}, 
\end{equation}
which is the same as \ref{eq:NPV}, with the difference, that now $r$ is the unknown variable. 

In the end it needs to be emphasized that the effective discount rate is in between the risk-free rate and the rate for which the company can borrow money (WACC for example). If these two values are identical, meaning the investor can find creditors who consider him to be a risk-free debtor, then this new algorithm is useless since that implies the effective interest rate being the risk-free rate. 


\section{New valuation technique}\footnote{Come up with a clever name for it.}
<Discussion about SDT format is missing, T, S, A, reward and probabilities. Reward is substituted, probabilities of future states are products of individual probabilities, assuming their independence. How do we get the probabilities? What the new valuation technique should do:>  

A valuation of a real project with given strategy is a process of assigning current monetary value to a vector of future FCFs, with values modeled by a complex probability distribution conditioned on that strategy. A valuation of a project is then the maximum over all valuations with the given strategy. 

The complex nature of individual future FCFs comes from the many uncertain parameters that influence such FCF. It might be demand in the given time interval, price of input raw materials and labor, previous decisions influencing the cost per unit parameter, where these decisions themselves can be for example influenced by the previous prices of raw materials. 

It can be felt that even with allowing for small amounts of uncertainty and further decision making in the project, the complexity rises extremely. This is why, in the spirit of SDT, we will compute the value gradually, starting from the time horizon of a project, gradually maximizing the utility by our actions going from the horizon, while keeping in mind the time value of money. 

The classical approach for solving decision making problems in SDT is to find a strategy that maximizes the expected reward in the following fashion: 
\begin{equation}
	content...
\end{equation}
,where .... 

This maximization is then solved by a backward induction, called dynamic programming, with computation of the respective value functions in each given state of the project. This algorithm results not only in the expected cumulative value of rewards obtained, but as a bonus an optimal strategy, that describes optimal actions in each state of the project. 

The new valuation algorithm is based on this idea of backward induction, however due to specifics of project valuation several steps need to be adjusted. 

When a backward induction is used in the classic dynamic programming, the bellman equation
\begin{equation}
	eq
\end{equation}
 is used to make a step back in time and value all states in the time epoch one lower from the values of states in the following time epoch. To incorporate the economical ideas about risk and time value of money, this step needs to be significantly adjusted. 
 
 All the following ideas concern a concept of "exchanging" or "identifying" different sources of value (money) to a "cash in time $t$. 
 
 
 <Take the $C_{t+}|a_t$ FCF at the end of epoch $t$, and the expected cash equivalent of being in the given next state. Add them together and get a certain cash equivalent value of that. Then do the same with potential cash outflows in the beginning of the $t$ epoch, then value this cash flow by the algorithm that values time in money. Maximize over all actions. 

Starting with the bellman equation: 
\begin{equation}
	content...
\end{equation}

we need to 

First, lets emphasize that reward in our sense has two types, first $C_{t-}$ obtained after a decision made in time $t$ and second obtained at the end of the time epoch $t$ $C_{t+}$. For example buying a power plant results in $C_{t-}$, while cash from selling its power results in $C_{t+}$. 

The new bellman equation wants to maximize a cash equivalent in time $C_{t-}$. First, lets talk about the cash $C_{t+}$ and cash equivalent $V(s_t)$ obtained at the time $C_{t-}$. To embrace the idea of risk-averse investors, the certain equivalent of this uncertain FCF and its aggreagted future equivalent $V(s_t)$ is not derived as the expected cash value, but as the cash value, that has the same utility as is the expected utility of the $C_{t-}$ and $V(s_t)$: 

\begin{equation}
	content...
\end{equation}

This certain equivalence of FCF is also done for the $C_{t-}$ type, where is usually less uncertainty. 
\begin{equation}
	content...
\end{equation}

Now we have two values of cash equivalent to be obtained in the beginning and the end of the time epoch $t$, $Eq_{t-}$ and $Eq_{t+}$. Now the concept of time value of money is to be embraced. To determine the final cash equivalent value of the uncertain $C_{t-}$, $C_{t+}$ $V(s_{t+1})$ in terms of $C_{t-}$ dollars, we need to use the algorithm presented in section \ref{} for determining the discount for $Eq_{t+}$. 

If the algorithm can be understood as a function, say $A(\cdot)$, then the final expected cash equivalent of $C_{t-}$, $C_{t+}$, $V(s_t+1)$ can be computed as: 
\begin{equation}
	V(s_t|a_t)=Eq_{t-}+A(Eq_{t+}).
\end{equation}

By maximization over these values for different possible actions $\mathbf{A_t(s_t)}$ the optimal action, together with the value of future cash flows is obtained: 

\begin{equation}
	V(s_t) = \max_{a_t\in\mathbf{A_t(s_t)}}V(s_t|a_t)
\end{equation}


Now that we have come up with the adjusted bellman equation, we can substitute this step in dynamic programming and use it to the full extend of SDT. 

The value of a project is then obtained by the backwards induction as $V(s_0)$. 

\subsection{Modelling FCF}
< Talk here more about how the randomness in FCF. $C_{t-}$ is a random variable with its distribution influenced by the state $s_t$ and its usually simple, while $C_{t+}$ is a random variable influenced by the state $s_t$ generally in a more complex way. Usually it is a evolution of prices according to some process.> 
The FCF aggregates all individual transactions of a project in given time period. In general each project has spend money on inputs (raw materials, supplier goods, labor,...) which are transformed to products that are sold on the market. This thesis views the price of each input as a general random process and its parameters are a function of the volume of each input. 

FCF is thus a value of a random process in one time instant

\begin{equation}
	FCF(q)=\sum_{inputs} -p_i(q*s_i)*q*s_i+p_o(q)*q
\end{equation}
, where $p_i$ is a price of input given the output quantity $q$, $s_i$ is a parameter that say how many units of input are needed to get the output and $p_o$ is the price of produced output. 

The quantity of production $q$ and the transformation parameter can usually be controlled by actions at least to some extend, while the prices are usually governed by a random process of respective movement of supply and demand curves. 

The modeling of supply and demand curves is in this thesis as follows: 

< I dont know much about modeling of this, is there some additional value in modeling the curves, or can the prices by simply random processes and prices their realizations?> 

This results in the parametric model of FCF:
\begin{equation}
	C_{t+}(\Theta,a_t,s_t) = \sum_{inputs} -p_i(\Theta,s-t,q(a_t))*s_i)*q(a_t)*s_i+p_o(\Theta, s-t, q(a_t))*q, 
\end{equation}

\subsection{Problems}

\begin{itemize}
	\item Granularity of time intervals might influence the valuation because of non-linearity of utility function. 10*U(1) != U(10)... Summing over utility of selling one barel of oil 
	\item Utility function preferences might vary in time. 
\end{itemize}




\subsection{Sets $\mathbf{T}, \mathbf{S_t}, \mathbf{B_t}$}
All of the sets $\mathbf{T}, \mathbf{U_t}, \mathbf{B_t}$ come from the model of a valuation problem.

The number and frequency of time periods is determined by $\mathbf{T}$, when the most usual approach is to have $\mathbf{T}$ as a finite number of yearly periods. This can represent either a duration of project rights (for example in mining) or rights for a cash flow share (for example from bridge tolls), or such fuzzy future, where nobody really knows what will happen with the project 50 years from now. 

The set of possible branches $\mathbf{B_t}$ comes from the project manager. He needs to identify the project alteration possibilities in each time period $t \in \mathbf{T}$. The set $\mathbf{B_t}$ is small most of the time, however in cases, when for example a start of a variable that is modeled by binomial tree is dependent on the strategy, the set $\mathbf{B_t}$ can grow rather quickly. The example is again a bridge project, where the number of toll-paying customers in time $t$ depends on a time period in which the bridge was finished. 


And finally, the values of an environment state $\mathbf{U_t}$ are determined by a model of the outer world. The set $\mathbf{U_t}$ should be able to capture the uncertainty about all important parameters for the project while remaining as simple as possible. A classical example is a binomial tree of input prices for our process (oil, software engineer's salary).



\chapter{Valuation of projects in multiple-source industries}
<Explain the class, say what are the examples, what uncertainty these industries need to cope with, what are the options? > 

The class of .... valuation problems is ideal for demonstration of the usability of the newly developed valuation technique. Due to the inherit uncertainty in this field and many actions that can be undertaken, the additional value  assigned to the investment opportunity can be significant. 

We start with a rigorous mathematical definition of this class of valuation techniques in terms of SDT. Then we pick one example and promptly show that the number of possible states is exponential with respect to... Approximate dynamic programming techniques like Q-learning or SARSA were developed in order to solve exactly these types of problems. Due to their strengths and only a minor flaws their usage is justified. 

\section{Power company}
<Complete valuation of new power plant project by the new technique>

<Complete valuation of new power plant project by ROA>  

\section{Public transportation/Water treatment/}
<Complete valuation of ... by the new technique>

<Complete valuation of ... by ROA>  

\chapter{Discussion}
The new approach is better because it solves the current problems with ... Also the applicability of the new approach is in my opinion broader since it can address multiple sources of uncertainty. Furthermore the power of the decision making process is kept in the hands of the decision maker through creation of prior distributions. The manager is guided through the world of utility functions and priors, which both can be created from a set of simple questions about gambles and beliefs of the manager. The creation and usage of the utility and prior density functions are fool-proof in a sense of mathematical coherence. 

\chapter{Conclusions}
In my master's thesis I have rigorously compared the state-of-the-art valuation techniques used in present investment companies. I have shown the advantages and disadvantages of real option analysis  and stochastic decision theory. The combination of these, which I call ...,  yields a new view on the world of risky investments that empowers the decision maker and thus allows for better adoption in the rigid environment of investing. 


















\chapter{Inspiration}

he, in my opinion, natural idea of interpretation of ROA in terms of SDT. 



The new valuation approach should incorporate the advantages of ROA into the stable framework of SDT, improving the performance of each approach individually, namely it should:

\begin{itemize}
	\item Capture uncertainty of a project
	\item Allow managers to implement their own approach to risk. 
	\item Enable to rigorously handle a time devaluation of money according to the profile of the company making the investment. 
	\item Allow to systematically compare projects in a portfolio to find the best candidates for an actual investment. 
	\item <Add all other qualities the new valuation technique should have> \footnote{For example allow for Bayesian learning, cope with a high-dimensional problems, multiple uncertainties,... }
\end{itemize}



\section{Black-Scholes Merton model}
Only four parameters and one assumption is needed to determine a value of an option according to BSM model for option pricing. Assume that the market is complete, and thus the law of one price holds \cite{}. Then to value a option you need to know only its time to maturity, its strike price, the current price of the underlying stock and its volatility as follows \cite{BerDeM:09}: 
\begin{equation}
C = SN(d_1) - PV(K)N(d_2), 
\label{BSMModelEq}
\end{equation}
where $S$ is the strike price, $PV(K)$ is a price of a bond paying K on the expiration day of the option and $N(d)$ is a cumulative normal distribution, probability that a normally distributed variable is less than $d$. Value of $d_1$ and $d_2$ is then defined as: 
\begin{equation}
d_1 = \frac{ln(S/PV(K))}{\sigma \sqrt{T}}+\frac{\sigma \sqrt{T}}{2}
d_2 = d_1 - \sigma \sqrt{T}
\end{equation}

The dependency of the price of an option is positive in case of volatility and time to maturity Increasing these parameters leads to a higher option price. On the contrary the rise in current stock price or strike price of the options lowers the value of an option. 



\section{Project and cash flow}

\begin{definition}
	A project is defined as a piece of planned work or an activity that is finished over a period of time and intended to achieve a particular purpose, mainly an increase of company's or individual's wealth\footnote{First part comes from Cambridge dictionary. }.
\end{definition}

Examples of a project are: 
\begin{itemize}
	\item developing a cooper mine; 
	\item innovation of chemical processes in an oil refinery;
	\item upgrade of current machinery in a production line; 
	\item changing the form of software development philosophy towards agile practices.
\end{itemize}

When examining the expression max E\{NPV(Options)\} four observations come to mind. 

First, the maximization is over some set of control strategies. This set can be generally large, even uncountable. Due to the class of the problems that are addressed in this thesis, the actions made by a manager are not expected to be continuous, not even very frequent. This would result in an assumption of small control strategy space, at least for now. 


 
 
\section{Bachelor's thesis parts that could be useful for TeX styling}




\begin{algorithm}
	\caption{Finding the optimal policy for a \textit{single system} MDP with known $P$}\label{alg:SingleKnown}
	\begin{algorithmic}[1]
		\Require{$\mathcal{M}=(\textbf{T},\textbf{S},\textbf{A},P,R)$}
		\State$ \varphi_N^{o}(s) \gets 0$, $\forall s \in \mathbf{S} $ \Comment{Based on Definition \ref{ValueF}.}
		\State $t \gets N$ 
		\While{$t\ne 0$}
		\For{ each $s \in \{1,2,...,|\mathbf{S}|\}$}
		\State $\varphi_{t-1}^{o}(s) \gets Equation$ $(\ref{DynProgEq})$ \Comment{With known $P$ and $\varphi_{t}^{o}$}
		\EndFor
		\State $t \gets t-1$
		\EndWhile
		\State $\pi_{0}^{o}(s) \gets argmax$ $\varphi_0^{o}(s)$ $ \forall s\in \mathbf{S}$, \Comment{Deriving the optimal policy}
		\State	\Return{$\pi_{0}^{o}$}
	\end{algorithmic}
\end{algorithm}


\pagestyle{plain}
\bibliographystyle{plain}
\bibliography{fr}


\end{document}
